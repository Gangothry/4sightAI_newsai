<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EENADU AI JOURNALIST COPILOT</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>

    <!-- Sidebar and Toggle Button -->
    <div class="sidebar-container">
        <div class="toggle-square" onclick="toggleSessionList()"></div>
        <button class="toggle-button" onclick="toggleSessionList()">‚ò∞</button>
        <div class="sidebar" id="sidebar">
            <h2>NEWS HIGHLIGHTS</h2>
            <div id="sessionList"></div>
        </div>
    </div>

    <!-- Main Content -->
    <div class="main-content" id="mainContent">
        <div class="container">
            <header>
                <h1>
                    <img src="logo.png" alt="Logo" width="250"> EENADU AI JOURNALIST COPILOT
                </h1>
            </header>

            <!-- Session Section -->
            <section id="sessionSection">
                <label for="sessionId">Session ID:</label>
                <input type="text" id="sessionId" placeholder="Session ID will be auto-generated" readonly>
                <button id="startSession">üöÄ Start Action</button>
            </section>

            <!-- News Section -->
            <section id="newsSection">
                <h3>Last Updated News</h3>
                <div id="compiledSpeechText"></div>
            </section>

            <!-- Action Selection -->
            <section id="actionSelection">
                <label for="actionSelect">Choose Action:</label>
                <select id="actionSelect">
                    <option value="record">üéô Start Recording</option>
                    <option value="upload">üìÅ Upload Audio</option>
                </select>
            </section>

            <!-- Recording Controls -->
            <section id="recordingControls" style="display:none;">
                <button id="startRecording">üé§ Start Recording</button>
                <button id="stopRecording" disabled>‚èπ Stop Recording</button>
                <button id="submitRecording" disabled>üì§ Submit</button>
                <p id="transcript">Transcript will appear here...</p>
            </section>

            <!-- Upload Controls -->
            <section id="uploadControls" style="display:none;">
                <label for="audioFile">Upload Audio:</label>
                <input type="file" id="audioFile">
                <button id="uploadAudio">üéß Upload and Transcribe Audio</button>
            </section>

            <!-- Session End -->
            <section id="endSessionSection">
                <button id="endSession">üîö End Session</button>
            </section>

            <!-- Output Section -->
            <section id="outputSection">
                <div class="output">
                    <h3>Output</h3>
                    <pre id="outputText"></pre>
                </div>
                <button id="showDifference" style="display: none;">Show Difference</button>
            </section>

            <!-- Loading Spinner -->
            <div class="loading" id="loading">
                <span class="loading-symbol"></span>
                <span id="loadingMessage">Loading, please wait...</span>
            </div>
        </div>
    </div>

    <script>
        // Initialize speech recognition
        let recognition;
        let isRecording = false;
        let recordedText = "";

        function showLoading(message) {
            const loadingElement = document.getElementById("loading");
            loadingElement.innerText = message;
            loadingElement.style.display = "block";
        }

        function hideLoading() {
            const loadingElement = document.getElementById("loading");
            loadingElement.style.display = "none";
        }

        // Toggle sidebar visibility
        function toggleSessionList() {
            const sidebar = document.getElementById('sidebar');
            const mainContent = document.getElementById('mainContent');
            if (sidebar.style.display === 'none') {
                sidebar.style.display = 'block';
                mainContent.style.marginLeft = '290px';
                mainContent.style.width = 'calc(100% - 290px)';
            } else {
                sidebar.style.display = 'none';
                mainContent.style.margin = 'auto';
                mainContent.style.width = '70%';
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            const sessionIdElement = document.getElementById('sessionId');
            const startSessionButton = document.getElementById('startSession');
            const actionSelect = document.getElementById('actionSelect');
            const recordingControls = document.getElementById('recordingControls');
            const uploadControls = document.getElementById('uploadControls');
            const startRecordingButton = document.getElementById('startRecording');
            const stopRecordingButton = document.getElementById('stopRecording');
            const submitButton = document.getElementById('submitRecording');
            const uploadAudioButton = document.getElementById('uploadAudio');
            const loadingElement = document.getElementById('loading');
            const transcriptElement = document.getElementById('transcript');

            // Auto-generate session ID
            sessionIdElement.value = `session-${Date.now()}`;

            // Toggle between recording and upload controls
            actionSelect.addEventListener('change', () => {
                if (actionSelect.value === 'record') {
                    recordingControls.style.display = 'block';
                    uploadControls.style.display = 'none';
                } else {
                    recordingControls.style.display = 'none';
                    uploadControls.style.display = 'block';
                }
            });

            // Setup Web Speech API for speech recognition
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.lang = 'te-IN'; // Set the language to Telugu
                recognition.interimResults = true;
                recognition.continuous = true;

                recognition.onresult = (event) => {
                    let interimTranscript = '';
                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        if (event.results[i].isFinal) {
                            recordedText += event.results[i][0].transcript;
                        } else {
                            interimTranscript += event.results[i][0].transcript;
                        }
                    }
                    transcriptElement.innerText = "Recorded Text: " + recordedText + interimTranscript;
                    submitButton.disabled = false;
                    hideLoading();
                };

                recognition.onerror = (event) => {
                    console.error("Error occurred in speech recognition: ", event.error);
                    alert("Speech recognition error: " + event.error);
                    hideLoading();
                };

                // Start recording
                startRecordingButton.addEventListener('click', () => {
                    if (!isRecording) {
                        recognition.start();
                        startRecordingButton.disabled = true;
                        stopRecordingButton.disabled = false;
                        isRecording = true;
                        showLoading('Recording... Please speak now.');
                    }
                });

                // Stop recording
                stopRecordingButton.addEventListener('click', () => {
                    if (isRecording) {
                        recognition.stop();
                        isRecording = false;
                        startRecordingButton.disabled = false;
                        stopRecordingButton.disabled = true;
                        showLoading('Processing recorded text...');
                    }
                });
            } else {
                alert("Your browser does not support Speech Recognition.");
            }

            // Submit the recorded text
            submitButton.addEventListener('click', () => {
                submitTeluguText(recordedText);
            });

            // Start session and handle actions
            startSessionButton.addEventListener('click', startSession);
            uploadAudioButton.addEventListener('click', uploadAudio);
            document.getElementById('endSession').addEventListener('click', endSession);
        });

// Function to fetch the compiled speech-to-text data based on session ID
async function fetchCompiledSpeechToText(sessionId) {
    // Define the URL for the API call using the session ID
    const url = `https://foursightai-v2-0.onrender.com/fetch-session/${sessionId}`;

    try {
        // Make a GET request to the API
        const response = await fetch(url, {
            method: "GET", // Request method
            headers: {
                "Content-Type": "application/json" // Header for content type
            }
        });

        // Check if the response is not okay (status outside of 200-299)
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }

        // Parse the response as JSON
        const data = await response.json();

        // If compiled speech text exists, display it, otherwise, display a default message
        const compiledSpeechText = data.compiled_speech_to_text || "Please provide new news item!!.";

        // Update the DOM element with the compiled speech-to-text data
        document.getElementById("compiledSpeechText").innerText = compiledSpeechText;
    } catch (error) {
        // Log any errors and display an error message in the DOM
        console.error("Error fetching compiled speech text:", error);
        document.getElementById("compiledSpeechText").innerText = "Error fetching data.";
    }
}
// Function to show the loading spinner
function showLoading(message) {
    const loadingElement = document.getElementById("loading");
    loadingElement.style.display = "block"; // Show the loading element
    loadingElement.innerHTML = `
        <div class="loading-symbol"></div>
        ${message}
    `;
}

// Function to hide the loading spinner
function hideLoading() {
    const loadingElement = document.getElementById("loading");
    loadingElement.style.display = "none"; // Hide the loading element
}

// Function to start a new session
async function startSession() {
    const sessionId = document.getElementById("sessionId").value;
    const url = "https://foursightai-v2-0.onrender.com/start-session/";
    const payload = {
        session_id: sessionId,
        language: "te-IN"
    };

    try {
        showLoading("Starting session...");
        const response = await fetch(url, {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }

        const data = await response.json();
        document.getElementById("outputText").innerText = data.message;

        // Fetch and display the compiled speech text
        fetchCompiledSpeechToText(sessionId);
    } catch (error) {
        console.error("Error starting session:", error);
    } finally {
        hideLoading();
    }
}

// Function to upload audio and transcribe it
async function uploadAudio() {
    const sessionId = document.getElementById("sessionId").value;
    const fileInput = document.getElementById("audioFile");
    const file = fileInput.files[0];
    const url = "https://foursightai-v2-0.onrender.com/upload-audio/";
    const formData = new FormData();
    formData.append("session_id", sessionId);
    formData.append("file", file);
    formData.append("language", "te-IN");

    try {
        showLoading("Uploading and transcribing audio...");
        const response = await fetch(url, {
            method: "POST",
            body: formData
        });

        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }

        const data = await response.json();
        document.getElementById("outputText").innerText = "Transcribed Text: " + data.transcribed_text;
    } catch (error) {
        console.error("Error uploading audio:", error);
    } finally {
        hideLoading();
    }
}

// Function to submit Telugu text to the entry API
async function submitTeluguText(recordedText) {
    const sessionId = document.getElementById("sessionId").value;
    const url = "https://foursightai-v2-0.onrender.com/telugu-text-entry/";
    const payload = {
        session_id: sessionId,
        language: recordedText
    };

    console.log("Submitting text to Telugu Text Entry API:", payload); // Log payload for debugging

    try {
        showLoading("Submitting text...");
        const response = await fetch(url, {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }

        const data = await response.json();
        console.log("API Response:", data); // Log API response for debugging

        // Display the API response in the output container
        document.getElementById("outputText").innerText = "Telugu Spoken Text: " + data.text;
    } catch (error) {
        console.error("Error submitting text:", error);
    } finally {
        hideLoading();
    }
}

// Function to end the session and display compiled text
async function endSession() {
    const sessionId = document.getElementById("sessionId").value;
    const url = `https://foursightai-v2-0.onrender.com/end-session/`;

    try {
        showLoading("Ending session...");
        const response = await fetch(url, {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            },
            body: JSON.stringify({ session_id: sessionId })
        });

        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }

        const data = await response.json();

        // Store compiled_speech_to_text and cleaned_speech_to_text.cleaned_text in global variables
        window.compiledSpeechToText = data.compiled_speech_to_text;
        window.cleanedSpeechToText = data.cleaned_speech_to_text.cleaned_text;

        // Print the entire response with proper formatting and spacing
        document.getElementById("outputText").innerHTML = `
            <strong>Compiled Speech to Text:</strong> ${data.compiled_speech_to_text}<br>
            <strong>Cleaned Speech to Text:</strong> ${data.cleaned_speech_to_text.cleaned_text}<br>
            <strong>Category Of Spoken Text:</strong> ${data.cleaned_speech_to_text.categorized_text}<br>
            <strong>Location of Spoken Text:</strong> ${data.cleaned_speech_to_text.location_text}<br>
            <strong>Cleaned File Text:</strong> ${data.cleaned_file_text}<br>
            <strong>Category Of File Text:</strong> ${data.cleaned_file_text.categorized_text}<br>
            <strong>Location of File Text:</strong> ${data.cleaned_file_text.location_text}<br>
        `;

        // Show the 'Show Difference' button
        document.getElementById("showDifference").style.display = "block";
    } catch (error) {
        console.error("Error ending session:", error);
    } finally {
        hideLoading();
    }
}


function showDifferences() {
    // Use the globally stored data from the endSession function
    const compiledSpeechToText = window.compiledSpeechToText; // Get from global variable
    const cleanedSpeechToText = window.cleanedSpeechToText;   // Get from global variable

    // Split the texts into arrays for word-by-word comparison
    const compiledArray = compiledSpeechToText.split(/\s+/);
    const cleanedArray = cleanedSpeechToText.split(/\s+/);

    let differenceText = "";

    // Compare word by word and highlight differences
    compiledArray.forEach((word, index) => {
        if (word !== cleanedArray[index]) {
            differenceText += `<span style="background-color: yellow;">${word}</span> `;
        } else {
            differenceText += `${word} `;
        }
    });

    // Display the difference text in the outputText container with added gap and bold headings
    document.getElementById("outputText").innerHTML = `
    <strong>Cleaned Speech to Text:</strong><br>${cleanedSpeechToText}<br><br>
    <strong>Changes made by AI:</strong><br>${differenceText}
    `;
}


// Add event listener to "Show Difference" button
document.getElementById("showDifference").addEventListener("click", showDifferences);

        document.addEventListener('DOMContentLoaded', () => {
    const sessionList = document.getElementById('sessionList');
    const sessionIdElement = document.getElementById('sessionId');
    const outputText = document.getElementById('outputText');
    
    // Load sessions when the page is loaded
    loadSessions();

    async function loadSessions() {
    const url = "https://foursightai-v2-0.onrender.com/sessions/"; // Corrected URL

    try {
        const response = await fetch(url);
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }

        const data = await response.json();
        sessionList.innerHTML = '';

        if (data.sessions && data.sessions.length > 0) {
            for (const sessionId of data.sessions) {
                // Fetch session details to get the title
                const sessionDetails = await fetchSessionDetails(sessionId);
                
                const div = document.createElement('div');
                div.className = 'session-item';
                div.textContent = sessionDetails.title || sessionId; // Use title or fallback to sessionId
                div.setAttribute("data-session-id", sessionId);
                div.onclick = () => updateSessionId(sessionId);
                sessionList.appendChild(div);
            }
        } else {
            sessionList.innerHTML = '<div>No sessions available</div>';
        }
    } catch (error) {
        console.error("Error loading sessions:", error);
        sessionList.innerHTML = '<div>Error loading sessions</div>';
    }
}

async function fetchSessionDetails(sessionId) {
    const url = `https://foursightai-v2-0.onrender.com/fetch-session/${sessionId}/`;

    try {
        showLoading("Fetching session details...");
        const response = await fetch(url);
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }

        const data = await response.json();
        return {
            title: data.cleaned_speech_to_text.title || "No Title", // Fetch title or fallback
            compiledSpeechToText: data.compiled_speech_to_text,
            cleanedSpeechToText: data.cleaned_speech_to_text.cleaned_text,
            cleanedFileText: data.cleaned_file_text
        };
    } catch (error) {
        console.error("Error fetching session details:", error);
        return {
            title: "Error fetching title"
        };
    } finally {
        hideLoading();
    }
}


async function updateSessionId(sessionId) {
    sessionIdElement.value = sessionId;
    await fetchSessionDetails(sessionId);
    fetchCompiledSpeechToText(sessionId);
}

});

    </script>
</body>

</html>
